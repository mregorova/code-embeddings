# code-embeddings
My NLP pet-project, which is used for code embeddings research in programmimg.

# To start with: выбор датасета
В постановке задачи был рекомендован датасет CodeSearchNet, однако за основу я взяла найденный на Codeforces датасет Code_contests от Deepmind. Для представленной задачи его преимущество в том, что код (который является решением задач на cf) представлен сразу на нескольких языках программирования, что позволяет оценить качество модели путем сравнения эмбеддингов, полученных на основе разного синтаксиса предложений.

Множество полученных решений выглядит так:
<img src="https://github.com/mregorova/code-embeddings/blob/main/images/solutions1.png" width="500" height="361">

# Выбор языковой модели
Прежде всего, стоит рассмотреть версии моделей, предназначенные для работы с кодом, такие как codeBERT и codeT5, так как они более специализированы, чем сами по себе BERT и T5. Также для работы с кодом используются такие модели, как OpenAI, CodeGeeX, code2vec и многие другие. 
Основное исследование и сравнение мтерик было проведено при помощи codeBERT.

# Получение эмбеддингов и анализ качества

